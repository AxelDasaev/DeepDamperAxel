{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "S-adwM_W5daG",
    "outputId": "3bb95ead-d712-4e1e-988b-1f2388f23062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jzbaQ6TN5wdF",
    "outputId": "66ef2895-3ee5-47f8-90d2-c3a5472699c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "umXsNQ7A4a2P",
    "outputId": "e48654f2-5195-4acf-fa15-c702023fda5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DeepDamperAxel'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 27 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (27/27), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/AxelDasaev/DeepDamperAxel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "KyEVk5Op4a2T",
    "outputId": "4e86031d-28fa-460e-fd22-e4ead307ca8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/DeepDamperAxel\n"
     ]
    }
   ],
   "source": [
    "%cd DeepDamperAxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_hbVYQU4a2W"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"axeldasaev@gmail.com\"\n",
    "!git config --global user.name \"AxelDasaev\"\n",
    "!git remote rm origin\n",
    "!git remote add origin https://token@github.com/AxelDasaev/DeepDamperAxel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7V4bX-M4a2Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsZ_mveh4a2b"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tBAcp0w4a2e"
   },
   "outputs": [],
   "source": [
    "def read_json(name):\n",
    "    #print(name)\n",
    "    with open(name) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5wSe_Ks4a2h"
   },
   "outputs": [],
   "source": [
    "def data_proces(name,Deface=100,NumSam=200):\n",
    "    datos=read_json(name)\n",
    "    entradas=read_json('_'.join(('inp',name)))\n",
    "    train=np.array([[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]])\n",
    "    referencia=[0]\n",
    "    for key in datos.keys():\n",
    "        #print(len(datos[key]))\n",
    "        for k,exp in enumerate(datos[key]):\n",
    "            VelC=exp[\"velocity\"]\n",
    "            forceC=exp[\"force\"]\n",
    "            VelCj=[round(elem, 1) for elem in VelC]\n",
    "            Conj=set(VelCj)\n",
    "            infbar=100\n",
    "            for elem in list(Conj):\n",
    "                indices=[i for i,x in enumerate(VelCj) if x==elem]\n",
    "                for ind in range(len(indices)-1):\n",
    "                    if forceC[indices[ind]] == forceC[indices[ind+1]] and indices[ind]> 120:\n",
    "                        reference = [indices[ind],indices[ind+1]]\n",
    "                        break\n",
    "                    elif abs(forceC[indices[ind]]-forceC[indices[ind+1]])<infbar and indices[ind+1]-indices[ind]>20 and indices[ind+1]-indices[ind]<200 and indices[ind]> 120:\n",
    "                        tempref = [indices[ind],indices[ind+1]]\n",
    "                        infbar = abs(forceC[indices[ind]]-forceC[indices[ind+1]])\n",
    "                if 'reference' in locals():\n",
    "                    break\n",
    "            \n",
    "            if 'reference' in locals():    \n",
    "                Deface = reference[0]\n",
    "                NumSam = reference[1] - reference[0]\n",
    "                del reference\n",
    "            else:\n",
    "                Deface = tempref[0]\n",
    "                NumSam = tempref[1] - tempref[0]\n",
    "                del tempref\n",
    "            referencia.append(referencia[-1]+NumSam+1)\n",
    "            for element in range(NumSam+1):\n",
    "                caso=list()\n",
    "                caso.append(entradas[key][\"Ap\"])\n",
    "                caso.append(entradas[key][\"Ag\"])\n",
    "                caso.append(entradas[key][\"h\"])\n",
    "                caso.append(entradas[key][\"L\"])\n",
    "                caso.append(entradas[key][\"viscocidad\"])\n",
    "                caso.append(entradas[key][\"Ty\"][k]/1000)\n",
    "                caso.append((exp[\"velocity\"][element+Deface])*0.001)\n",
    "                caso.append(exp[\"displace\"][element+Deface])\n",
    "                caso.append(exp[\"force\"][element+Deface])\n",
    "                casonp=np.array(caso)\n",
    "                #print(len(casonp))\n",
    "                train=np.append(train,[casonp],axis=0)\n",
    "            \n",
    "    return train[2:][:],referencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zo2AGbFo4a2l"
   },
   "outputs": [],
   "source": [
    "def Target_C(data):\n",
    "    Arn=(data[0]+((data[1])/2))\n",
    "    Fn=((12*(data[4])*Arn*(data[6]/10))/((data[1])*data[2]*data[2]))\n",
    "    Fn=Fn*(data[0]*data[3])\n",
    "    Fty=data[8]-Fn\n",
    "    c=((Fty*data[2])/(data[3]*data[0]*data[5]*1000))\n",
    "    return Fty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oplZVXJW4a2o"
   },
   "outputs": [],
   "source": [
    "def force_limit(data):\n",
    "    Arn=(data[0]+((data[1])/2))\n",
    "    Fn=((12*(data[4])*Arn*(data[6]))/((data[1])*data[2]*data[2]))\n",
    "    Fn=Fn*(data[0]*data[3])\n",
    "    #c=2.07+((12*data[4]*data[0]*data[6])/((12*data[4]*data[0]*data[6])+(0.4*data[1]*data[2]*data[5])))\n",
    "    c=1.07\n",
    "    Fty= (c*data[3]*data[0]*data[5]*1000)/(data[2])\n",
    "    fr=Fn+Fty\n",
    "    #print(fr)\n",
    "    #print(data[8])\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DzE8TdBY4a2q"
   },
   "outputs": [],
   "source": [
    "train,refer=data_proces(\"twofluidexp.json\",Deface=120,NumSam=260)\n",
    "#rint(train.shape)\n",
    "#print(train[1:4])\n",
    "np.random.shuffle(train)\n",
    "#train[1:4,8:9].shape\n",
    "#print(train[20][])\n",
    "#print(refer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UW8ygv0p4a2t"
   },
   "outputs": [],
   "source": [
    "Train=np.array(train)[:,:8].astype(\"float32\")\n",
    "Target=np.array(train)[:,8:9].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZPwNSC_4a2x"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDiZSwIC4a20"
   },
   "source": [
    "## Arquitectura de la red usando el modelo de Keras por medio objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yw8YsM0W4a21"
   },
   "outputs": [],
   "source": [
    "class DeepDamper(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(DeepDamper, self).__init__()\n",
    "    self.HL1 = tf.keras.layers.Dense(15, input_shape=(8,) , activation='relu')\n",
    "    self.HL2 = tf.keras.layers.Dense(15, activation = 'relu')\n",
    "    self.HL3 = tf.keras.layers.Dense(15, activation = 'relu')\n",
    "    self.out = tf.keras.layers.Dense(1)\n",
    "    # Seleccionar una funcion de error, optimizador y metricas de evaluacion \n",
    "    self.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.HL1(inputs)\n",
    "    x = self.HL2(x)\n",
    "    x = self.HL3(x)\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwqExdHU4a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "667/667 [==============================] - ETA: 0s - loss: 108.6109\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 108.6109\n",
      "Epoch 2/100\n",
      "645/667 [============================>.] - ETA: 0s - loss: 92.4363\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 92.4424\n",
      "Epoch 3/100\n",
      "653/667 [============================>.] - ETA: 0s - loss: 91.1089\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 91.2186\n",
      "Epoch 4/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 90.9344\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.9618\n",
      "Epoch 5/100\n",
      "634/667 [===========================>..] - ETA: 0s - loss: 90.8808\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.8892\n",
      "Epoch 6/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 90.7749\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.8250\n",
      "Epoch 7/100\n",
      "647/667 [============================>.] - ETA: 0s - loss: 90.9730\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.8179\n",
      "Epoch 8/100\n",
      "651/667 [============================>.] - ETA: 0s - loss: 90.8219\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.7751\n",
      "Epoch 9/100\n",
      "644/667 [===========================>..] - ETA: 0s - loss: 90.6079\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.7607\n",
      "Epoch 10/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 90.7587\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.7196\n",
      "Epoch 11/100\n",
      "665/667 [============================>.] - ETA: 0s - loss: 90.6993\n",
      "Epoch 00011: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.7175\n",
      "Epoch 12/100\n",
      "655/667 [============================>.] - ETA: 0s - loss: 90.4594\n",
      "Epoch 00012: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.6378\n",
      "Epoch 13/100\n",
      "650/667 [============================>.] - ETA: 0s - loss: 90.6167\n",
      "Epoch 00013: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.6419\n",
      "Epoch 14/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 90.6622\n",
      "Epoch 00014: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.6101\n",
      "Epoch 15/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 90.5903\n",
      "Epoch 00015: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.5988\n",
      "Epoch 16/100\n",
      "649/667 [============================>.] - ETA: 0s - loss: 90.7972\n",
      "Epoch 00016: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.5735\n",
      "Epoch 17/100\n",
      "665/667 [============================>.] - ETA: 0s - loss: 90.5184\n",
      "Epoch 00017: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 2s 2ms/step - loss: 90.5312\n",
      "Epoch 18/100\n",
      "643/667 [===========================>..] - ETA: 0s - loss: 90.4698\n",
      "Epoch 00018: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.5244\n",
      "Epoch 19/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 90.5884\n",
      "Epoch 00019: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.4828\n",
      "Epoch 20/100\n",
      "653/667 [============================>.] - ETA: 0s - loss: 90.4498\n",
      "Epoch 00020: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.4615\n",
      "Epoch 21/100\n",
      "655/667 [============================>.] - ETA: 0s - loss: 90.5493\n",
      "Epoch 00021: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.4415\n",
      "Epoch 22/100\n",
      "659/667 [============================>.] - ETA: 0s - loss: 90.3885\n",
      "Epoch 00022: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.4443\n",
      "Epoch 23/100\n",
      "649/667 [============================>.] - ETA: 0s - loss: 90.2312\n",
      "Epoch 00023: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.3575\n",
      "Epoch 24/100\n",
      "644/667 [===========================>..] - ETA: 0s - loss: 90.2451\n",
      "Epoch 00024: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.3632\n",
      "Epoch 25/100\n",
      "661/667 [============================>.] - ETA: 0s - loss: 90.3621\n",
      "Epoch 00025: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.3112\n",
      "Epoch 26/100\n",
      "665/667 [============================>.] - ETA: 0s - loss: 90.2662\n",
      "Epoch 00026: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.3116\n",
      "Epoch 27/100\n",
      "648/667 [============================>.] - ETA: 0s - loss: 90.2118\n",
      "Epoch 00027: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.2675\n",
      "Epoch 28/100\n",
      "655/667 [============================>.] - ETA: 0s - loss: 90.3842\n",
      "Epoch 00028: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.2129\n",
      "Epoch 29/100\n",
      "642/667 [===========================>..] - ETA: 0s - loss: 90.3923\n",
      "Epoch 00029: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.2185\n",
      "Epoch 30/100\n",
      "644/667 [===========================>..] - ETA: 0s - loss: 90.0869\n",
      "Epoch 00030: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.1772\n",
      "Epoch 31/100\n",
      "659/667 [============================>.] - ETA: 0s - loss: 90.1446\n",
      "Epoch 00031: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.1417\n",
      "Epoch 32/100\n",
      "656/667 [============================>.] - ETA: 0s - loss: 90.0312\n",
      "Epoch 00032: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.1179\n",
      "Epoch 33/100\n",
      "647/667 [============================>.] - ETA: 0s - loss: 90.2379\n",
      "Epoch 00033: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.1089\n",
      "Epoch 34/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 90.0742\n",
      "Epoch 00034: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.0627\n",
      "Epoch 35/100\n",
      "644/667 [===========================>..] - ETA: 0s - loss: 89.9781\n",
      "Epoch 00035: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 90.0257\n",
      "Epoch 36/100\n",
      "666/667 [============================>.] - ETA: 0s - loss: 89.9377\n",
      "Epoch 00036: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.9123\n",
      "Epoch 37/100\n",
      "643/667 [===========================>..] - ETA: 0s - loss: 90.1059\n",
      "Epoch 00037: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.8947\n",
      "Epoch 38/100\n",
      "653/667 [============================>.] - ETA: 0s - loss: 89.8306\n",
      "Epoch 00038: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.8411\n",
      "Epoch 39/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 89.7759\n",
      "Epoch 00039: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.7925\n",
      "Epoch 40/100\n",
      "646/667 [============================>.] - ETA: 0s - loss: 89.7122\n",
      "Epoch 00040: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.6443\n",
      "Epoch 41/100\n",
      "655/667 [============================>.] - ETA: 0s - loss: 89.2908\n",
      "Epoch 00041: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.4225\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/667 [============================>.] - ETA: 0s - loss: 89.4658\n",
      "Epoch 00042: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.3404\n",
      "Epoch 43/100\n",
      "659/667 [============================>.] - ETA: 0s - loss: 89.3542\n",
      "Epoch 00043: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.2292\n",
      "Epoch 44/100\n",
      "645/667 [============================>.] - ETA: 0s - loss: 88.9922\n",
      "Epoch 00044: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 89.1206\n",
      "Epoch 45/100\n",
      "664/667 [============================>.] - ETA: 0s - loss: 89.0542\n",
      "Epoch 00045: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.9882\n",
      "Epoch 46/100\n",
      "659/667 [============================>.] - ETA: 0s - loss: 88.8780\n",
      "Epoch 00046: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.8918\n",
      "Epoch 47/100\n",
      "657/667 [============================>.] - ETA: 0s - loss: 88.7921\n",
      "Epoch 00047: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.7836\n",
      "Epoch 48/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 88.7008\n",
      "Epoch 00048: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.6500\n",
      "Epoch 49/100\n",
      "648/667 [============================>.] - ETA: 0s - loss: 88.4134\n",
      "Epoch 00049: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.5015\n",
      "Epoch 50/100\n",
      "656/667 [============================>.] - ETA: 0s - loss: 88.4887\n",
      "Epoch 00050: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.3670\n",
      "Epoch 51/100\n",
      "648/667 [============================>.] - ETA: 0s - loss: 88.2132\n",
      "Epoch 00051: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.2133\n",
      "Epoch 52/100\n",
      "646/667 [============================>.] - ETA: 0s - loss: 87.8682\n",
      "Epoch 00052: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 88.0256\n",
      "Epoch 53/100\n",
      "640/667 [===========================>..] - ETA: 0s - loss: 87.9314\n",
      "Epoch 00053: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 87.7897\n",
      "Epoch 54/100\n",
      "657/667 [============================>.] - ETA: 0s - loss: 87.5762\n",
      "Epoch 00054: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 87.5977\n",
      "Epoch 55/100\n",
      "637/667 [===========================>..] - ETA: 0s - loss: 87.4718\n",
      "Epoch 00055: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 87.3535\n",
      "Epoch 56/100\n",
      "653/667 [============================>.] - ETA: 0s - loss: 87.0670\n",
      "Epoch 00056: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 87.0954\n",
      "Epoch 57/100\n",
      "653/667 [============================>.] - ETA: 0s - loss: 86.5908\n",
      "Epoch 00057: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 86.7388\n",
      "Epoch 58/100\n",
      "648/667 [============================>.] - ETA: 0s - loss: 86.6002\n",
      "Epoch 00058: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 86.4884\n",
      "Epoch 59/100\n",
      "667/667 [==============================] - ETA: 0s - loss: 86.0400\n",
      "Epoch 00059: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 86.0400\n",
      "Epoch 60/100\n",
      "662/667 [============================>.] - ETA: 0s - loss: 85.9852\n",
      "Epoch 00060: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 85.8620\n",
      "Epoch 61/100\n",
      "639/667 [===========================>..] - ETA: 0s - loss: 85.3959\n",
      "Epoch 00061: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 85.4118\n",
      "Epoch 62/100\n",
      "644/667 [===========================>..] - ETA: 0s - loss: 85.3017\n",
      "Epoch 00062: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 84.9781\n",
      "Epoch 63/100\n",
      "638/667 [===========================>..] - ETA: 0s - loss: 84.7357\n",
      "Epoch 00063: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 84.5370\n",
      "Epoch 64/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 83.9433\n",
      "Epoch 00064: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 83.9672\n",
      "Epoch 65/100\n",
      "651/667 [============================>.] - ETA: 0s - loss: 83.5078\n",
      "Epoch 00065: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 83.4301\n",
      "Epoch 66/100\n",
      "663/667 [============================>.] - ETA: 0s - loss: 82.7704\n",
      "Epoch 00066: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 82.7423\n",
      "Epoch 67/100\n",
      "647/667 [============================>.] - ETA: 0s - loss: 81.8080\n",
      "Epoch 00067: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 81.7261\n",
      "Epoch 68/100\n",
      "642/667 [===========================>..] - ETA: 0s - loss: 81.0059\n",
      "Epoch 00068: saving model to training_1/cp.ckpt\n",
      "667/667 [==============================] - 1s 2ms/step - loss: 80.9007\n",
      "Epoch 69/100\n",
      " 34/667 [>.............................] - ETA: 0s - loss: 83.2246"
     ]
    }
   ],
   "source": [
    "DamperModel = DeepDamper()\n",
    "DamperModel.fit(x=Train, y=Target,batch_size =20, epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mL2caGkx4a25"
   },
   "outputs": [],
   "source": [
    "DamperModel.save('my_net') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8TubZw84a28"
   },
   "outputs": [],
   "source": [
    "!git add -A\n",
    "!git commit -m \"Se agrego entrenamiento1\"\n",
    "!git push -u origin master"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DeepDamper_Axel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
